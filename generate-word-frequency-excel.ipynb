{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7eccc09-c396-4ff5-8c41-0ef80f3038e9",
   "metadata": {},
   "source": [
    "# Generate Word Frequency in Audit Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa795e-4275-48be-9874-5bbb1dd9ceed",
   "metadata": {},
   "source": [
    "## Steps Taken\n",
    "\n",
    "1. Download the folder with audit reports from OneDrive\n",
    "2. Iterate through the folder and get the folders with each country's reports\n",
    "3. For each country's folder, get the country's reports\n",
    "4. Lemmatize the words in each report\n",
    "5. Get the frequency distribution of each text\n",
    "6. Filter the words to remove noise\n",
    "7. Enter the frequency distribution into a pandas dataframe\n",
    "8. Merge each country's frequency distributions into one dataframe with the words as rows and report name as column\n",
    "9. Enter each country as a spreadsheet in an excel workbook\n",
    "10. Delete the downloaded documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a33207fd-7635-44fa-a906-00a0d7e8c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to audit_reports; publicly accessible\n",
    "audit_reports_link = \"https://stir-my.sharepoint.com/:f:/g/personal/fkc3_stir_ac_uk/Esgp-VMQyzBClY5vpTP9TsYBTCb16iA3NvelLEJM53VEgQ?e=7ejaR3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26882d5-fae7-40c6-8a17-80640e94c52a",
   "metadata": {},
   "source": [
    "### 2. Iterate through the folder and create a dictionary to match each country to files within it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62caa145-bfa8-46fc-902a-525d575d274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdfminer.high_level import extract_text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017b0e49-73e6-433a-a0c2-5e3fb308a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_reports_file_path = \"./audit_reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa87889f-3be2-409f-b301-1bc05dc867f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_audit_report_dict = {}\n",
    "\n",
    "for root, dirs, files in os.walk(audit_reports_file_path):\n",
    "    if (dirs): # ignore the country folders as children\n",
    "        continue\n",
    "    country_audit_report_dict[root] = sorted(files);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caac5c2b-10ed-4246-93a2-ee33e28bf076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reports_as_text():\n",
    "    for country_folder_path, filenames in country_audit_report_dict.items():\n",
    "        for filename in filenames:\n",
    "            file_path = f'{country_folder_path}/{filename}'\n",
    "            text_file_path = file_path.replace('.pdf', '.txt') # text path of pdf\n",
    "            try:\n",
    "                if file_path.endswith('.txt') or os.path.isfile(text_file_path): continue\n",
    "\n",
    "                print(f'Doing {file_path}')               \n",
    "                text = extract_text(f'{file_path}').lower()\n",
    "\n",
    "                with open(text_file_path, 'w') as text_file:\n",
    "                    text_file.write(text)\n",
    "            \n",
    "            except:\n",
    "                print(f'{filename} has a problem')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1245c2-6121-45ed-b9d2-87bd7c6c354a",
   "metadata": {},
   "source": [
    "### 3. For each country's folder, get the country's reports as text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d5b15d-2999-4758-a5fb-39e20d0a9567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_texts_dict = {}\n",
    "\n",
    "for country_folder_path, filenames in country_audit_report_dict.items():\n",
    "    for filename in filenames:\n",
    "        # print(f'Doing {country_folder_path}/{filename}')\n",
    "        try:\n",
    "            if not filename.endswith('.txt'): continue\n",
    "\n",
    "            with open(f'{country_folder_path}/{filename}') as text:\n",
    "                # print(filename, text.readline())\n",
    "                if country_folder_path in country_texts_dict:\n",
    "                    country_texts_dict[country_folder_path][filename] = text.read();\n",
    "                    \n",
    "                elif country_folder_path not in country_texts_dict:\n",
    "                    country_texts_dict[country_folder_path] = {filename: text.read()}\n",
    "                    \n",
    "        except:\n",
    "            print(f'{filename} has a problem')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1464dee1-2a1f-4fcc-b4aa-f493a50744cf",
   "metadata": {},
   "source": [
    "### 4. Lemmatize the words in each report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dcd2fd3-aa14-47aa-9e7e-2acfba5e1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "for country_path in country_texts_dict.keys():\n",
    "    for report_name, report_text in country_texts_dict[country_path].items():\n",
    "        if report_text:\n",
    "            words_in_report = nltk.word_tokenize(report_text.lower()) \n",
    "\n",
    "            words_in_report = [lemmatizer.lemmatize(word) for word in words_in_report]\n",
    "\n",
    "            country_texts_dict[country_path][report_name] = words_in_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41e0e6-6b45-49e0-9dd9-ae4a6d0156b6",
   "metadata": {},
   "source": [
    "### 5. Get the frequency distribution of each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bed7ed5-af9d-46bc-aa5e-d23105eabeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_report_freq_dist_dict = {}\n",
    "\n",
    "for country_path in country_texts_dict.keys():\n",
    "    for report_name, report_words in country_texts_dict[country_path].items():\n",
    "        fdist = nltk.FreqDist(report_words)\n",
    "        '''\n",
    "        bigram_fdist = nltk.FreqDist(nltk.bigrams(report_words))\n",
    "        trigram_fdist = nltk.FreqDist(nltk.trigrams(report_words))\n",
    "\n",
    "        fdist.update(bigram_fdist)\n",
    "        fdist.update(trigram_fdist)\n",
    "        '''\n",
    "\n",
    "        if country_path in country_report_freq_dist_dict:\n",
    "            country_report_freq_dist_dict[country_path][report_name] = fdist\n",
    "        else:\n",
    "            country_report_freq_dist_dict[country_path] = {report_name: fdist}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70bb8a-c6d4-47d8-a5dc-ca4107357809",
   "metadata": {},
   "source": [
    "### 6. Filter the words to remove noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abaac18-1758-4d02-a339-cc49609408e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\nfor country_path in country_texts_dict.keys():\\n    for report_name, report_words in country_texts_dict[country_path].items():\\n        english_words = set(report_words) | set(words.words())\\n        english_words_without_stopwords = english_words - set(stopwords.words('english'))\\n        #report_words = list(filter(is_ideal_word, report_words))\\n        country_texts_dict[country_path][report_name] = english_words_without_stopwords\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove words made up numbers, symbols, stopwords and non-english words\n",
    "def is_ideal_word(word):\n",
    "    if word.isalpha() \\\n",
    "        and word not in stopwords.words('english'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "'''    \n",
    "for country_path in country_texts_dict.keys():\n",
    "    for report_name, report_words in country_texts_dict[country_path].items():\n",
    "        english_words = set(report_words) | set(words.words())\n",
    "        english_words_without_stopwords = english_words - set(stopwords.words('english'))\n",
    "        #report_words = list(filter(is_ideal_word, report_words))\n",
    "        country_texts_dict[country_path][report_name] = english_words_without_stopwords\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b70d1dd-247c-4975-9177-8781f7cef986",
   "metadata": {},
   "source": [
    "### 7. Enter the frequency distributions into one dataframe per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0524e-f9f2-4631-b146-7d4eb670c46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./audit_reports/Zambia to file\n",
      "Writing ./audit_reports/South-Africa to file\n",
      "Writing ./audit_reports/Nigeria to file\n",
      "Writing ./audit_reports/Kenya to file\n",
      "Writing ./audit_reports/Ghana to file\n",
      "Writing ./audit_reports/Malawi to file\n"
     ]
    }
   ],
   "source": [
    "country_report_df_dict = {}\n",
    "\n",
    "with pd.ExcelWriter('word-frequency.xlsx') as writer:\n",
    "    for country_path in country_report_freq_dist_dict.keys():\n",
    "        df = pd.DataFrame()\n",
    "        print(f'Writing {country_path} to file')\n",
    "    \n",
    "        for report_name, freq_dist in country_report_freq_dist_dict[country_path].items():\n",
    "            if df.empty:\n",
    "                df = pd.DataFrame.from_dict(dict(freq_dist), orient='index', columns=[report_name])\n",
    "            else:\n",
    "                other_df = pd.DataFrame.from_dict(dict(freq_dist), orient='index', columns=[report_name])\n",
    "                df = pd.merge(df, other_df, 'outer', left_index=True, right_index=True)\n",
    "\n",
    "        # save dataframe in the excel file\n",
    "    \n",
    "        df.to_excel(writer, sheet_name=f'{country_path.removeprefix(\"./audit_reports/\")}')\n",
    "        del df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bd1393-230c-4fd0-aac1-142eee6b9b29",
   "metadata": {},
   "source": [
    "### 8. Merge each country's frequency distributions into one dataframe with the words as rows and report name as column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0449e117-db80-46a3-a750-069e2851567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df_dict = {}\n",
    "'''\n",
    "for country_path in country_report_df_dict.keys():\n",
    "    df = pd.DataFrame()\n",
    "    for report_df in country_report_df_dict[country_path].values():\n",
    "        if df.empty:\n",
    "            df = report_df\n",
    "        else:\n",
    "            df = pd.merge(df, report_df, 'outer',left_index=True, right_index=True)\n",
    "    country_df_dict[country_path] = df\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9097bf4d-e08f-401a-bf0c-0ae0944836bd",
   "metadata": {},
   "source": [
    "### 9. Enter each country as a spreadsheet in an excel workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743fc9c5-43f1-4989-a8e0-60791f5e84a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with pd.ExcelWriter('word-frequency.xlsx') as writer:\n",
    "    for country_path, df in country_df_dict.items():\n",
    "        df.to_excel(writer, sheet_name=f'{country_path.removeprefix(\"./audit_reports/\")}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f3714-749b-4dc8-ab7a-c388160f30db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auditor-general-reports-analyses",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
