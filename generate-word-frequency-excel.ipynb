{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7eccc09-c396-4ff5-8c41-0ef80f3038e9",
   "metadata": {},
   "source": [
    "# Generate Word Frequency in Audit Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa795e-4275-48be-9874-5bbb1dd9ceed",
   "metadata": {},
   "source": [
    "## Steps Taken\n",
    "\n",
    "1. Download the folder with audit reports from OneDrive\n",
    "2. Iterate through the folder and get the folders with each country's reports\n",
    "3. For each country's folder, get the country's reports\n",
    "4. Lemmatize the words in each report\n",
    "5. Get the frequency distribution of each text\n",
    "6. Filter the words to remove noise\n",
    "7. Enter the frequency distribution into a pandas dataframe\n",
    "8. Merge each country's frequency distributions into one dataframe with the words as rows and report name as column\n",
    "9. Enter each country as a spreadsheet in an excel workbook\n",
    "10. Delete the downloaded documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a33207fd-7635-44fa-a906-00a0d7e8c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to audit_reports; publicly accessible\n",
    "audit_reports_link = \"https://stir-my.sharepoint.com/:f:/g/personal/fkc3_stir_ac_uk/Esgp-VMQyzBClY5vpTP9TsYBTCb16iA3NvelLEJM53VEgQ?e=7ejaR3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26882d5-fae7-40c6-8a17-80640e94c52a",
   "metadata": {},
   "source": [
    "### 2. Iterate through the folder and create a dictionary to match each country to files within it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62caa145-bfa8-46fc-902a-525d575d274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdfminer.high_level import extract_text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017b0e49-73e6-433a-a0c2-5e3fb308a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_reports_file_path = \"./audit_reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa87889f-3be2-409f-b301-1bc05dc867f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_audit_report_dict = {}\n",
    "\n",
    "for root, dirs, files in os.walk(audit_reports_file_path):\n",
    "    if (dirs): # ignore the country folders as children\n",
    "        continue\n",
    "    country_audit_report_dict[root] = sorted(files);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caac5c2b-10ed-4246-93a2-ee33e28bf076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reports_as_text():\n",
    "    for country_folder_path, filenames in country_audit_report_dict.items():\n",
    "        for filename in filenames:\n",
    "            file_path = f'{country_folder_path}/{filename}'\n",
    "            text_file_path = file_path.replace('.pdf', '.txt') # text path of pdf\n",
    "            try:\n",
    "                if file_path.endswith('.txt') or os.path.isfile(text_file_path): continue\n",
    "\n",
    "                print(f'Doing {file_path}')               \n",
    "                text = extract_text(f'{file_path}').lower()\n",
    "\n",
    "                with open(text_file_path, 'w') as text_file:\n",
    "                    text_file.write(text)\n",
    "            \n",
    "            except:\n",
    "                print(f'{filename} has a problem')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1245c2-6121-45ed-b9d2-87bd7c6c354a",
   "metadata": {},
   "source": [
    "### 3. For each country's folder, get the country's reports as text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d5b15d-2999-4758-a5fb-39e20d0a9567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_texts_dict = {}\n",
    "\n",
    "for country_folder_path, filenames in country_audit_report_dict.items():\n",
    "    for filename in filenames:\n",
    "        # print(f'Doing {country_folder_path}/{filename}')\n",
    "        try:\n",
    "            if not filename.endswith('.txt'): continue\n",
    "\n",
    "            with open(f'{country_folder_path}/{filename}') as text:\n",
    "                # print(filename, text.readline())\n",
    "                if country_folder_path in country_texts_dict:\n",
    "                    country_texts_dict[country_folder_path][filename] = text.read();\n",
    "                    \n",
    "                elif country_folder_path not in country_texts_dict:\n",
    "                    country_texts_dict[country_folder_path] = {filename: text.read()}\n",
    "                    \n",
    "        except:\n",
    "            print(f'{filename} has a problem')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1464dee1-2a1f-4fcc-b4aa-f493a50744cf",
   "metadata": {},
   "source": [
    "### 4. Lemmatize the words in each report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dcd2fd3-aa14-47aa-9e7e-2acfba5e1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "for country_path in country_texts_dict.keys():\n",
    "    for report_name, report_text in country_texts_dict[country_path].items():\n",
    "        if report_text:\n",
    "            words_in_report = nltk.word_tokenize(report_text.lower()) \n",
    "\n",
    "            words_in_report = [lemmatizer.lemmatize(word) for word in words_in_report]\n",
    "\n",
    "            country_texts_dict[country_path][report_name] = words_in_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41e0e6-6b45-49e0-9dd9-ae4a6d0156b6",
   "metadata": {},
   "source": [
    "### 5. Get the frequency distribution of each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bed7ed5-af9d-46bc-aa5e-d23105eabeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_report_freq_dist_dict = {}\n",
    "\n",
    "# remove words with numbers and those that are stopwords\n",
    "def clean_fdist(fdist):\n",
    "    return {word: freq for word, freq in fdist.items() if word.isalpha() and word not in set(stopwords.words('english'))}\n",
    "\n",
    "for country_path in country_texts_dict.keys():\n",
    "    for report_name, report_words in country_texts_dict[country_path].items():\n",
    "        fdist = nltk.FreqDist(report_words)\n",
    "        fdist = clean_fdist(fdist)\n",
    "\n",
    "        bigram_fdist = nltk.FreqDist(nltk.bigrams(report_words))\n",
    "        # join the words if the words are all alphabets\n",
    "        bigram_fdist = {' '.join(key): value for key, value in bigram_fdist.items() if ''.join(key).isalpha()}\n",
    "\n",
    "        trigram_fdist = nltk.FreqDist(nltk.trigrams(report_words))\n",
    "        trigram_fdist = {' '.join(key): value for key, value in trigram_fdist.items() if ''.join(key).isalpha()}\n",
    "        \n",
    "        fdist.update(bigram_fdist)\n",
    "        fdist.update(trigram_fdist)\n",
    "        \n",
    "        '''\n",
    "\n",
    "        fdist.update(bigram_fdist)\n",
    "        fdist.update(trigram_fdist)\n",
    "        '''\n",
    "\n",
    "        if country_path in country_report_freq_dist_dict:\n",
    "            country_report_freq_dist_dict[country_path][report_name] = fdist\n",
    "        else:\n",
    "            country_report_freq_dist_dict[country_path] = {report_name: fdist}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b70d1dd-247c-4975-9177-8781f7cef986",
   "metadata": {},
   "source": [
    "### 7. Enter the frequency distributions into one dataframe per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9b032ca-7ac2-4ac2-b3d1-103db52891f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./audit_reports/Zambia to file\n",
      "Completed writing to ./audit_reports/Zambia\n",
      "Writing ./audit_reports/South-Africa to file\n",
      "Completed writing to ./audit_reports/South-Africa\n",
      "Writing ./audit_reports/Nigeria to file\n",
      "Completed writing to ./audit_reports/Nigeria\n",
      "Writing ./audit_reports/Kenya to file\n",
      "Completed writing to ./audit_reports/Kenya\n",
      "Writing ./audit_reports/Ghana to file\n",
      "Completed writing to ./audit_reports/Ghana\n",
      "Writing ./audit_reports/Malawi to file\n",
      "Completed writing to ./audit_reports/Malawi\n",
      "Writing ./audit_reports/Tanzania to file\n",
      "Completed writing to ./audit_reports/Tanzania\n",
      "Writing ./audit_reports/Uganda to file\n",
      "Completed writing to ./audit_reports/Uganda\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter('word-frequency.xlsx', engine='xlsxwriter') as writer:\n",
    "    for country_path in country_report_freq_dist_dict.keys():\n",
    "        df = pd.DataFrame()\n",
    "        print(f'Writing {country_path} to file')\n",
    "    \n",
    "        for report_name, freq_dist in country_report_freq_dist_dict[country_path].items():\n",
    "            if df.empty:\n",
    "                df = pd.DataFrame.from_dict(dict(freq_dist), orient='index', columns=[report_name])\n",
    "            else:\n",
    "                other_df = pd.DataFrame.from_dict(dict(freq_dist), orient='index', columns=[report_name])\n",
    "                df = pd.merge(df, other_df, 'outer', left_index=True, right_index=True)\n",
    "\n",
    "        df.to_excel(writer, sheet_name=f'{country_path.removeprefix(\"./audit_reports/\")}')\n",
    "        print(f'Completed writing to {country_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f3714-749b-4dc8-ab7a-c388160f30db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auditor-general-reports-analyses",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
